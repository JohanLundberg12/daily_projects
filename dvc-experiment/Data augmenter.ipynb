{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cae5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed=1)\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebbadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamVidDataSet_open:\n",
    "    def __init__(self, imgs_path, labels_path, transform):\n",
    "        self.imgs_path = imgs_path\n",
    "        self.labels_path = labels_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs = os.listdir(self.imgs_path)\n",
    "        self.labels = list(\n",
    "            map(lambda x: x[:-4] + \"_L.png\", self.imgs)\n",
    "        )  # see train_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.imgs_path, self.imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        image_out = self.transform(image)\n",
    "\n",
    "        label_loc = os.path.join(self.labels_path, self.labels[idx])\n",
    "        label = Image.open(label_loc).convert(\"RGB\")\n",
    "        label_out = self.transform(label)\n",
    "\n",
    "        return image_out, label_out, self.imgs[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ae59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (128, 128)\n",
    "transformation = transforms.Compose([transforms.Resize(input_size, 0)])\n",
    "camvid = CamVidDataSet_open(\n",
    "    \"./CamVid/train/\", \"./CamVid/train_labels/\", transform=transformation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f655515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining endings and augmentation\n",
    "\n",
    "# _00: original data\n",
    "# _01: horizontal transformation\n",
    "# _02: shape transformation (resize and crop)\n",
    "# _03: brightness transformation\n",
    "# _04: contrast transformation\n",
    "# _05: gaussian noise\n",
    "# _06: total: all transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68428ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining all transformations\n",
    "\n",
    "aug_horizontal = transforms.RandomHorizontalFlip(p=1)\n",
    "\n",
    "shape_aug = transforms.RandomResizedCrop((128, 128), scale=(0.1, 0.9), ratio=(0.5, 2))\n",
    "\n",
    "brightness_aug = transforms.ColorJitter(brightness=0.5, contrast=0, saturation=0, hue=0)\n",
    "\n",
    "contrast_aug = transforms.ColorJitter(\n",
    "    brightness=0, contrast=0.5, saturation=0.2, hue=0.1\n",
    ")\n",
    "\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=0.001):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \"(mean={0}, std={1})\".format(\n",
    "            self.mean, self.std\n",
    "        )\n",
    "\n",
    "\n",
    "transform_gaussian = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0, 1),\n",
    "        AddGaussianNoise(\n",
    "            0.0, 0.001\n",
    "        ),  # Change 0.001 to be a higher number of we need more noise - shall also be done in the AddGaussia\n",
    "        transforms.ToPILImage(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "total_aug_data = transforms.Compose(\n",
    "    [aug_horizontal, shape_aug, brightness_aug, contrast_aug, transform_gaussian]\n",
    ")\n",
    "\n",
    "total_aug_labels = transforms.Compose([aug_horizontal, shape_aug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dea1d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_augment = \"./CamVid/train_augment/\"\n",
    "path_labels_augmemt = \"./CamVid/train_labels_augment/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e4ebf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(camvid)):\n",
    "    # Define current image and labels\n",
    "    img = camvid[i][0]\n",
    "    labels = camvid[i][1]\n",
    "    name = camvid[i][2]\n",
    "    name_labels = camvid[i][3]\n",
    "\n",
    "    # Save original data and labels\n",
    "    img.save(path_augment + name + \"_00\", format=\"png\")\n",
    "    labels.save(path_labels_augmemt + name_labels + \"_00\", format=\"png\")\n",
    "\n",
    "    # Horizontal flip\n",
    "    img_flip = aug_horizontal(img)\n",
    "    labels_flip = aug_horizontal(labels)\n",
    "\n",
    "    img_flip.save(path_augment + name + \"_01\", format=\"png\")\n",
    "    labels_flip.save(path_labels_augmemt + name_labels + \"_01\", format=\"png\")\n",
    "\n",
    "    # Crop and resize\n",
    "    rand_1 = np.random.randint(1000)\n",
    "\n",
    "    torch.manual_seed(rand_1)\n",
    "    img_crop = shape_aug(img)\n",
    "\n",
    "    torch.manual_seed(rand_1)\n",
    "    labels_crop = shape_aug(labels)\n",
    "\n",
    "    img_crop.save(path_augment + name + \"_02\", format=\"png\")\n",
    "    labels_crop.save(path_labels_augmemt + name_labels + \"_02\", format=\"png\")\n",
    "\n",
    "    # Brightness\n",
    "    img_bright = brightness_aug(img)\n",
    "\n",
    "    img_bright.save(path_augment + name + \"_03\", format=\"png\")\n",
    "    labels.save(path_labels_augmemt + name_labels + \"_03\", format=\"png\")\n",
    "\n",
    "    # Colour and saturation\n",
    "    img_contrast = contrast_aug(img)\n",
    "\n",
    "    img_contrast.save(path_augment + name + \"_04\", format=\"png\")\n",
    "    labels.save(path_labels_augmemt + name_labels + \"_04\", format=\"png\")\n",
    "\n",
    "    # Gaussian noise\n",
    "\n",
    "    img_gaussian = transform_gaussian(img)\n",
    "\n",
    "    img_gaussian.save(path_augment + name + \"_05\", format=\"png\")\n",
    "    labels.save(path_labels_augmemt + name_labels + \"_05\", format=\"png\")\n",
    "\n",
    "    # Combined augmentation\n",
    "    rand_2 = np.random.randint(1000)\n",
    "\n",
    "    torch.manual_seed(rand_2)\n",
    "    img_combined = total_aug_data(img)\n",
    "\n",
    "    torch.manual_seed(rand_2)\n",
    "    labels_combined = total_aug_labels(labels)\n",
    "\n",
    "    img_combined.save(path_augment + name + \"_06\", format=\"png\")\n",
    "    labels_combined.save(path_labels_augmemt + name_labels + \"_06\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54364c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
